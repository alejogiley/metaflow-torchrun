A introduction to running distributed model training with PyTorch, using distributed data parallelism:
```
python flow.py run
```